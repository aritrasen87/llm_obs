{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a58757f",
   "metadata": {},
   "source": [
    "### Agent Tool call evaluation with PyTest & LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7c67e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c854f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Langsmith params for observability\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['LANGSMITH_PROJECT'] = 'LLM_OBS_YT'\n",
    "os.environ['LANGSMITH_TRACING']=\"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765a376",
   "metadata": {},
   "source": [
    "### RAG Vector DB Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153f24b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/y3hsdcy135b1wr5gzcw3b3kr0000gn/T/ipykernel_13249/1780032375.py:12: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceBgeEmbeddings(\n",
      "/Users/aritrasen/Documents/code/agents_observability/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('sample_doc.pdf')\n",
    "docs = loader.load()\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "db = Chroma.from_documents(docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c764724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab22b21",
   "metadata": {},
   "source": [
    "### LangGraph Agent with RAG + WebSearch (MultiAgent Supervisor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af792b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Langsmith params for observability\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['LANGSMITH_PROJECT'] = 'LLM_OBS_YT'\n",
    "os.environ['LANGSMITH_TRACING']=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855aae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db125c",
   "metadata": {},
   "source": [
    "### Tools Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0241d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/y3hsdcy135b1wr5gzcw3b3kr0000gn/T/ipykernel_13249/1911882425.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(max_results=5)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701660a",
   "metadata": {},
   "source": [
    "### Create specialized Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66376a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Research Agent for Web Search\n",
    "\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    docs = tavily_tool.invoke({\"query\": query})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    return web_results\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[web_search],\n",
    "    name=\"research_expert\",\n",
    "   prompt=\"You are a world class researcher with access to web search.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8670d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAG Agent\n",
    "\n",
    "def rag_search(query:str):\n",
    "    \"Function to do RAG search\"\n",
    "    docs = retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "    return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "        [\n",
    "            f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content\n",
    "            for i, doc in enumerate(docs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "rag_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[rag_search],\n",
    "    name=\"rag_expert\",\n",
    "    prompt=\"You are a RAG tool with access to transformer applications on Deep Learning related tasks.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fbd2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "\n",
    "workflow = create_supervisor(\n",
    "    agents=[research_agent, rag_agent],\n",
    "    model=llm,\n",
    "    prompt=(\n",
    "        \"You are a supervisor managing a web search expert and a RAG search expert. \"\n",
    "        \"For current events and information, use research_agent.\"\n",
    "        \"For transformer related information , use rag_agent.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compile and run\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e60513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Task supervisor with path ('__pregel_pull', 'supervisor') wrote to unknown channel is_last_step, ignoring it.\n",
      "Task supervisor with path ('__pregel_pull', 'supervisor') wrote to unknown channel remaining_steps, ignoring it.\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "result_rag = app.invoke({\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about mutlihead attention in transformers\"\n",
    "        }\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503e0d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Tell me about mutlihead attention in transformers', additional_kwargs={}, response_metadata={}, id='558409c8-4e5b-4996-aaf9-ada47663f470'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3xH5iVqO8Cy6O9iSogoZ6YQx', 'function': {'arguments': '{}', 'name': 'transfer_to_rag_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 110, 'total_tokens': 124, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BuLRYCoyQdG5Oqfw4UA9rjkOD5qqk', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='supervisor', id='run--c6bf665c-ecbb-46d8-a3e7-365df6dc19e7-0', tool_calls=[{'name': 'transfer_to_rag_expert', 'args': {}, 'id': 'call_3xH5iVqO8Cy6O9iSogoZ6YQx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 110, 'output_tokens': 14, 'total_tokens': 124, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Successfully transferred to rag_expert', name='transfer_to_rag_expert', id='879f1ace-021d-451c-a9b1-625f6e7ad139', tool_call_id='call_3xH5iVqO8Cy6O9iSogoZ6YQx'),\n",
       "  AIMessage(content='Multi-head attention is a crucial component of the transformer architecture, introduced by Vaswani et al. in their seminal paper in 2017. It enhances the model\\'s ability to focus on different parts of an input sequence simultaneously, thus capturing diverse contextual information.\\n\\n### Key Aspects of Multi-Head Attention:\\n\\n1. **Scaled Dot-Product Attention**: \\n   - Before discussing multi-head attention, it\\'s important to understand the scaled dot-product attention mechanism, which forms the basis of this process. It uses three matrices: Query (Q), Key (K), and Value (V). The attention score is computed as:\\n     \\\\[\\n     \\\\text{Attention}(Q, K, V) = \\\\text{softmax}\\\\left(\\\\frac{QK^T}{\\\\sqrt{d_k}}\\\\right)V\\n     \\\\]\\n   - Here, \\\\(d_k\\\\) is the dimension of the key vectors, and the softmax function ensures that the output values are in the range [0, 1], representing the attention weights.\\n\\n2. **Multiple Attention Heads**:\\n   - In multi-head attention, multiple attention mechanisms (or \"heads\") are applied in parallel. Each head computes the attention output independently, allowing the model to learn from different representations and focus on various parts of the input sequence.\\n   - After calculating attention outputs from each head, these can be concatenated and linearly transformed into a single matrix to create a rich representation of the input data.\\n\\n3. **Benefits of Multi-Head Attention**:\\n   - By using multiple attention heads, the transformer can capture information from different representation subspaces at different positions, improving its ability to learn the intricate relationships within the data.\\n   - This means that the model can simultaneously consider various aspects of the input sequence, making it particularly effective for tasks such as language translation and other natural language processing applications.\\n\\n4. **Architecture Integration**:\\n   - Multi-head attention is integrated into both the encoder and decoder modules of the transformer architecture. In the encoder, it processes input embeddings, while in the decoder, it is used to pay attention to both the encoder\\'s output and the previously generated tokens.\\n\\nOverall, the implementation of multi-head attention in transformers significantly enhances their performance on a variety of tasks by providing the ability to draw on a richer set of contextual information.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 467, 'prompt_tokens': 2101, 'total_tokens': 2568, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BuLReQBCK9YjREA3dkFMKNqSKB3c3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='rag_expert', id='run--2348c497-958d-435a-b2bb-1978374c0165-0', usage_metadata={'input_tokens': 2101, 'output_tokens': 467, 'total_tokens': 2568, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='rag_expert', id='6116a987-0ab1-43c2-acaa-9b315f4e437e', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '752b608a-be9a-4e62-9cf9-cbee05d4dfa9', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='e918d73a-ace0-4248-bca4-e94ab30a1ace', tool_call_id='752b608a-be9a-4e62-9cf9-cbee05d4dfa9'),\n",
       "  AIMessage(content='I’ve provided you with an overview of multi-head attention in transformers. If you need further information or clarification on any specific aspect, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 666, 'total_tokens': 698, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BuLRmEVKTlkaswWJkTQm401o2wDQT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='supervisor', id='run--c5bd1de3-cc13-433b-97c7-5e10eb99e26b-0', usage_metadata={'input_tokens': 666, 'output_tokens': 32, 'total_tokens': 698, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f90e9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('result_rag.pkl', 'wb') as f:\n",
    "    pkl.dump(result_rag, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed740cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I’ve provided you with an overview of multi-head attention in transformers. If you need further information or clarification on any specific aspect, feel free to ask!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rag['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3771e9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task supervisor with path ('__pregel_pull', 'supervisor') wrote to unknown channel is_last_step, ignoring it.\n",
      "Task supervisor with path ('__pregel_pull', 'supervisor') wrote to unknown channel remaining_steps, ignoring it.\n"
     ]
    }
   ],
   "source": [
    "result_websearch = app.invoke(\n",
    "    {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"who is the winner of Last T20 Cricket World Cup?\"\n",
    "        }\n",
    "    ]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08595e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'India won the last T20 Cricket World Cup, which concluded on June 29, 2024.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_websearch['messages'][-1].content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b5bbe3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who is the winner of Last T20 Cricket World Cup?', additional_kwargs={}, response_metadata={}, id='73c4cf74-04ae-4aed-b89e-35088e5dab0b'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Rqp1UoDnANqHA5xBB0WjeHEF', 'function': {'arguments': '{}', 'name': 'transfer_to_research_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 113, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BuLRpcNT6aF3siAd67lXD34A0UvZI', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='supervisor', id='run--b54764f4-73e6-4679-af5e-c9b7c15de344-0', tool_calls=[{'name': 'transfer_to_research_expert', 'args': {}, 'id': 'call_Rqp1UoDnANqHA5xBB0WjeHEF', 'type': 'tool_call'}], usage_metadata={'input_tokens': 113, 'output_tokens': 14, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Successfully transferred to research_expert', name='transfer_to_research_expert', id='aa9bf4e6-2760-4372-a2f0-4a8ce311b2f9', tool_call_id='call_Rqp1UoDnANqHA5xBB0WjeHEF'),\n",
       "  AIMessage(content='India is the winner of the last T20 Cricket World Cup, having claimed their second title by winning the tournament that concluded on June 29, 2024.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 815, 'total_tokens': 849, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BuLRyLxQA3th9wuBHie4NT1SbiZla', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='research_expert', id='run--4b7421ad-c163-410a-b3de-d2b99fbaab03-0', usage_metadata={'input_tokens': 815, 'output_tokens': 34, 'total_tokens': 849, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='research_expert', id='89bfe6aa-7bbd-4516-baec-362ae4f412a6', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '7b7f2307-ad42-4426-b587-255a706e6b5c', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='e3bc3ac1-9bff-48a8-a871-8db79e941782', tool_call_id='7b7f2307-ad42-4426-b587-255a706e6b5c'),\n",
       "  AIMessage(content='India won the last T20 Cricket World Cup, which concluded on June 29, 2024.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 236, 'total_tokens': 258, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-BuLS0G0UAo6qAUGeaDvlTKlCLJVN4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='supervisor', id='run--2bd4bea2-58ed-412a-8cb2-93b0bc9b518c-0', usage_metadata={'input_tokens': 236, 'output_tokens': 22, 'total_tokens': 258, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_websearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf31ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_websearch.pkl', 'wb') as f:\n",
    "    pkl.dump(result_websearch, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7287a4d4",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e12c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rag = pkl.load(open('result_rag.pkl', 'rb'))\n",
    "result_websearch = pkl.load(open('result_websearch.pkl', 'rb'))\n",
    "\n",
    "agent_responses = [result_rag , result_websearch] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8043348",
   "metadata": {},
   "source": [
    "### Testing tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69fc2142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tell me about mutlihead attention in transformers',\n",
       " 'who is the winner of Last T20 Cricket World Cup?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = ['Tell me about mutlihead attention in transformers',\n",
    "             'who is the winner of Last T20 Cricket World Cup?']\n",
    "\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0e54914",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_tool_calls = [['transfer_to_rag_expert', 'transfer_back_to_supervisor'],\n",
    "                       ['transfer_to_research_expert', 'transfer_back_to_supervisor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96e0a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b974a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_calls(messages: List[Any]) -> List[str]:\n",
    "    \"\"\"Extract tool call names from messages, safely handling messages without tool_calls.\"\"\"\n",
    "    tool_call_names = []\n",
    "    for message in messages:\n",
    "        # Check if message is a dict and has tool_calls\n",
    "        if isinstance(message, dict) and message.get(\"tool_calls\"):\n",
    "            tool_call_names.extend([call[\"name\"].lower() for call in message[\"tool_calls\"]])\n",
    "        # Check if message is an object with tool_calls attribute\n",
    "        elif hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "            tool_call_names.extend([call[\"name\"].lower() for call in message.tool_calls])\n",
    "    \n",
    "    return tool_call_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f66e0e",
   "metadata": {},
   "source": [
    "### Agent tool call evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd61b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from langsmith import testing as t\n",
    "\n",
    "@pytest.mark.langsmith\n",
    "@pytest.mark.parametrize(\n",
    "    \"prompts, expected_tool_calls\",\n",
    "    [   # Pick some examples with prompts and expected tool call names\n",
    "        (prompts[0],expected_tool_calls[0]),\n",
    "        (prompts[1],expected_tool_calls[1]),\n",
    "    ],\n",
    ")\n",
    "def test_agent_tool_calls(prompts, expected_tool_calls):\n",
    "\n",
    "    \"\"\"Test that the agent calls the expected tools.\"\"\"\n",
    "    # Initialize the agent\n",
    "    result = agent.invoke(prompts)\n",
    "    # Extract tool calls from the agent's response\n",
    "    executed_tool_calls = extract_tool_calls(result['messages'])\n",
    "                        \n",
    "    # Check if all expected tool calls are in the extracted ones\n",
    "    missing_calls = [call for call in expected_tool_calls if call.lower() not in executed_tool_calls]\n",
    "    \n",
    "    t.log_outputs({\n",
    "                \"missing_calls\": missing_calls,\n",
    "                \"executed_tool_calls\": executed_tool_calls,\n",
    "                \"expected_tool_calls\": expected_tool_calls\n",
    "            })\n",
    "\n",
    "    # Test passes if no expected calls are missing\n",
    "    assert len(missing_calls) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be88f8",
   "metadata": {},
   "source": [
    "Notebook to Py Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ccd216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aritrasen/Documents/code/github/llm_obs/research.py:20: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(max_results=5)\n"
     ]
    }
   ],
   "source": [
    "from research import AppAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921c0eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aritrasen/Documents/code/github/llm_obs/research.py:38: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceBgeEmbeddings(\n",
      "/Users/aritrasen/Documents/code/agents_observability/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "app = AppAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52899101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task supervisor with path ('__pregel_pull', 'supervisor') wrote to unknown channel is_last_step, ignoring it.\n",
      "Task supervisor with path ('__pregel_pull', 'supervisor') wrote to unknown channel remaining_steps, ignoring it.\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke('When is the next Ind vs Eng 4th Test Match?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e162b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='When is the next Ind vs Eng 4th Test Match?', additional_kwargs={}, response_metadata={}, id='2d305718-ca07-437d-bc63-a6794b15bb48'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_meI27kE9GF9243cZTbBez6RS', 'function': {'arguments': '{}', 'name': 'transfer_to_research_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 114, 'total_tokens': 128, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-Buttgn1tn8xHM5PkCylAA9xK9UUCN', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='supervisor', id='run--716ed8aa-6d61-4e42-80ac-8aaa3be073d4-0', tool_calls=[{'name': 'transfer_to_research_expert', 'args': {}, 'id': 'call_meI27kE9GF9243cZTbBez6RS', 'type': 'tool_call'}], usage_metadata={'input_tokens': 114, 'output_tokens': 14, 'total_tokens': 128, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Successfully transferred to research_expert', name='transfer_to_research_expert', id='b9de0e86-7d9e-473b-b7e6-da44feff38e1', tool_call_id='call_meI27kE9GF9243cZTbBez6RS'),\n",
       "  AIMessage(content='The next India vs England 4th Test match is scheduled to be held from **July 23 to July 27, 2025** at Emirates Old Trafford, Manchester. The match will start at **10:00 AM GMT** (11:00 AM local time).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 2174, 'total_tokens': 2231, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-ButtyeYYBPi1HN190Vfd2nQm7Zsj3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='research_expert', id='run--9c0b813e-6c4b-49c3-a1bc-680efc991535-0', usage_metadata={'input_tokens': 2174, 'output_tokens': 57, 'total_tokens': 2231, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='research_expert', id='54219122-7a80-4a14-bc75-889975ddd203', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'b6e19c1a-3d28-40f2-924f-cfae0305f422', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='9c407620-dd67-4eb1-af6a-4561adcc2b55', tool_call_id='b6e19c1a-3d28-40f2-924f-cfae0305f422'),\n",
       "  AIMessage(content='The next India vs England 4th Test match is scheduled to take place from July 23 to July 27, 2025, at Emirates Old Trafford in Manchester. The match will start at 10:00 AM GMT (11:00 AM local time).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 260, 'total_tokens': 315, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-Butu0DOKMZCUzXSBiUt51qpqpa7Lc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='supervisor', id='run--db9c9429-d897-443c-80d6-a9fc67fa3da3-0', usage_metadata={'input_tokens': 260, 'output_tokens': 55, 'total_tokens': 315, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d919b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
