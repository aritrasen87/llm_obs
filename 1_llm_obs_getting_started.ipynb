{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96354e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "# os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac391a",
   "metadata": {},
   "source": [
    "### Langsmith params for observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60702586",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Langsmith params for observability\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['LANGSMITH_PROJECT'] = 'LLM_OBS_YT'\n",
    "os.environ['LANGSMITH_TRACING']=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51bfb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f5232",
   "metadata": {},
   "source": [
    "### RAG Vector DB Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a6b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('sample_doc.pdf')\n",
    "docs = loader.load()\n",
    "\n",
    "###  BGE Embddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "### Creating Retriever using Vector DB\n",
    "db = Chroma.from_documents(docs, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c73f2",
   "metadata": {},
   "source": [
    "### Trace with LangSmith and Types of Traces (useful when we don't use LangChain/LangGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6078b45d",
   "metadata": {},
   "source": [
    "LangSmith supports many different types of Runs - you can specify what type your Run is in the @traceable decorator. The types of runs are:\n",
    "\n",
    "- LLM: Invokes an LLM\n",
    "- Retriever: Retrieves documents from databases or other sources\n",
    "- Tool: Executes actions with function calls\n",
    "- Chain: Default type; combines multiple Runs into a larger process\n",
    "- Prompt: Hydrates a prompt to be used with an LLM\n",
    "- Parser: Extracts structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2e31a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7018b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Answer the Question based only on the following Context. If the answer is not in the context, say 'I don't know'.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a252527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(run_type=\"llm\")\n",
    "def llm(messages: List[dict]):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10e8819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(run_type=\"chain\")\n",
    "def rag_chain(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd3e8f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain(\"Tell me about mutlihead attention in transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72ab1d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-head attention in transformers is a crucial component that allows the neural network to learn and capture diverse characteristics of input sequential data. It enhances the representation of input contexts by merging information from distinct features of the attention mechanism, which can operate over both short and long ranges. This approach enables the attention mechanism to function jointly, resulting in improved network performance.\n",
      "\n",
      "In the multi-head attention module, the scaled dot-product attention function is applied in parallel across multiple heads. Each head performs the attention mechanism using its own set of learnable weights (WkQ, WkK, and WkV). The outputs from each head are then concatenated and linearly transformed into a single matrix with the expected dimension. This parallel execution of attention allows the model to capture different aspects of the input data simultaneously, contributing to the overall effectiveness of the transformer architecture.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f04c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain(\"Tell me about Encoder module in transformers\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_observability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
